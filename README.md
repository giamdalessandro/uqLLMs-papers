# uqLLMs-papers
Paper on Uncertainty Quantification for Large Language models.

### MCQA
- Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering (Molfese et al, 2025)

### Uncertainty
- Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs (ACL25)(Vazhentsev et al, 2025)
- A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions (Shorinwa et al, 2024)
- Benchmarking LLMs via Uncertainty Quantification (Ye et al, 2024)
- Uncertainty Estimation and Quantification for LLMs: A Simple  Supervised Approach (Liu et al., 2024)
- Conformal Prediction with Large Language Models for Multi-Choice Question Answering (Kumar et al, 2023)

### Hallucinations
- Why Language Models Hallucinate (Kalai et al, 2025)

### Attention Sinks
- What are you sinking? A geometric approach on attention sink (Ruscio et al, 2025)
- Why do LLMs attend to the first token? (Barbero et al., 2025)
- Efficient Streaming Language Models with Attention Sinks (Xiao et al, 2024)
