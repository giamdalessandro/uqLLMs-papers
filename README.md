# uqLLMs-papers
Papers on Uncertainty Quantification for Large Language models.


## Uncertainty
<details>
<summary><strong>Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs</strong> — (Vazhentsev et al, 2025)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2505.20045)  
- [Code](#)
</details>

<details>
<summary><strong>A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions</strong> — (Shorinwa et al, 2024)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2412.05563)  
- [Code](#)
</details>

<details>
<summary><strong>Benchmarking LLMs via Uncertainty Quantification</strong> — (Ye et al, 2024)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2401.12794)  
- [Code](#)
</details>

<details>
<summary><strong>Uncertainty Estimation and Quantification for LLMs: A Simple  Supervised Approach</strong> — (Liu et al., 2024)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2404.15993)  
- [Code](#)
</details>

<details>
<summary><strong>Conformal Prediction with Large Language Models for Multi-Choice Question Answering</strong> — (Kumar et al, 2023)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2305.18404)  
- [Code](#)
</details>


## Hallucinations
<details>
<summary><strong>Why Language Models Hallucinate</strong> — (Kalai et al, 2025)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2509.04664)  
- [Code](#)
</details>


## Attention Maps

### Sinks
<details>
<summary><strong>What are you sinking? A geometric approach on attention sink</strong> — (Ruscio et al, 2025)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2508.02546)  
- [Code](#)
</details>

<details>
<summary><strong>Why do LLMs attend to the first token?</strong> — (Barbero et al., 2025)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2504.02732)  
- [Code](#)
</details>  

<details>
<summary><strong>Efficient Streaming Language Models with Attention Sinks</strong> — (Xiao et al, 2024)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/pdf/2309.17453)  
- [Code](https://github.com/mit-han-lab/streaming-llm)
</details>  


## MCQA
<details>
<summary><strong>Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering</strong> — (Molfese et al, 2025)</summary>

**Summary:**  
A few lines describing the core ideas.
- [PDF](https://arxiv.org/abs/2503.14996)  
- [Code](#)
</details>