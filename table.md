## Uncertainty
| Title                                                                                                                        | Authors           | Year | Summary                                | Links                                               |
| ---------------------------------------------------------------------------------------------------------------------------- | ----------------- | ---- | -------------------------------------- | --------------------------------------------------- |
| *Uncertainty-Aware Attention Heads: Efficient Unsupervised Uncertainty Quantification for LLMs*                              | Vazhentsev et al. | 2025 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2505.20045) · [Code](#) |
| *A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions* | Shorinwa et al.   | 2024 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2412.05563) · [Code](#) |
| *Benchmarking LLMs via Uncertainty Quantification*                                                                           | Ye et al.         | 2024 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2401.12794) · [Code](#) |
| *Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach*                                           | Liu et al.        | 2024 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2404.15993) · [Code](#) |
| *Conformal Prediction with Large Language Models for Multi-Choice Question Answering*                                        | Kumar et al.      | 2023 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2305.18404) · [Code](#) |

## Halluciantion
| Title                             | Authors      | Year | Summary                                | Links                                               |
| --------------------------------- | ------------ | ---- | -------------------------------------- | --------------------------------------------------- |
| *Why Language Models Hallucinate* | Kalai et al. | 2025 | A few lines describing the core ideas. | [PDF](https://arxiv.org/pdf/2509.04664) · [Code](#) |


## Multi-Choice Question Answering
| Title                                                                                                               | Authors        | Year | Summary                                | Links                                               |
| ------------------------------------------------------------------------------------------------------------------- | -------------- | ---- | -------------------------------------- | --------------------------------------------------- |
| *Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering* | Molfese et al. | 2025 | A few lines describing the core ideas. | [PDF](https://arxiv.org/abs/2503.14996) · [Code](#) |

## bonus: Attention Maps
| Title                                                                                                               | Authors        | Year | Summary                                | Links                                               |
| ------------------------------------------------------------------------------------------------------------------- | -------------- | ---- | -------------------------------------- | --------------------------------------------------- |
| *Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM Evaluation in Multiple-Choice Question Answering* | Molfese et al. | 2025 | A few lines describing the core ideas. | [PDF](https://arxiv.org/abs/2503.14996) · [Code](#) |

